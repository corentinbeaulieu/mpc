#%YAML 1.1
# Yaml version 1.1 is needed to avoid 'Map keys must be unique' error
# when parsing yaml file with yamllint.
# Gitlab yaml parser is broken and does not regognise the %YAML header...
# TODO: Uncomment previous header when gitlab has been fixed.
---
#Available stages to run in 'automatic' processing:
# For convenience, implicit stages have been made explicit here...
stages:
  - Initialization
  - Regular Installation
  - Basic Testing
  - Regular Testing
  - Benchmarks
  - Applications
  - Breaking tests
  - Configurations
  - Finalization
  - Release

# Add clone variables for concurent PIPELINES
variables:
  GL_PIPELINE_PATH: $CI_BUILDS_DIR/GL_$CI_PIPELINE_ID
  GL_BUILD_DIR: $GL_PIPELINE_PATH/build
  GL_INSTALL_DIR: $GL_PIPELINE_PATH/install
  GIT_DEPTH: 1 # No need to clone the whole history
  #GIT_CLONE_PATH: $GL_PIPELINE_PATH/$CI_RUNNER_ID/$CI_CONCURRENT_ID
  PCVS_COMMAND: pcvs -v run --override --profile-path ${GL_PIPELINE_PATH}/mpc_ci/mpc.yml --print errors -S

.pcvs_prepare: &pcvs_prepare
  - export CI_PCVS_DIR="$GL_PIPELINE_PATH/step_$(echo "$CI_JOB_NAME" | sed -e "s/ /_/g")/"
  - test -d "${CI_PCVS_DIR}" && rm -rf "${CI_PCVS_DIR}"
  - mkdir -p "${CI_PCVS_DIR}"
  - cd "${GL_PIPELINE_PATH}"
  - test "x${CI_BRANCH}" != "x" && echo "Using CI branch ${CI_BRANCH}"
  - mkdir mpc_ci 2>"/dev/null"
      && git clone "https://gitlab-ci-token:${CI_JOB_TOKEN}@gitlab.ccc.ocre.cea.fr/cea-mpc-team/mpc-ci.git" $(test "x${CI_BRANCH}" != "x" && echo "-b ${CI_BRANCH}") "mpc_ci"
      || sleep 5s
  - cd "${CI_PCVS_DIR}"
  - echo "Step run from ${CI_PCVS_DIR}"
  - source ${GL_INSTALL_DIR}/mpcvars.sh
  - echo "MPC loaded from ${GL_INSTALL_DIR}/mpcvars.sh"
  - source "$(ccc_home -u mpc)"/gitlab-runner/spack_organizer_inti/setup.sh
  - spack env activate pcvs
  - module load pmix

# Template nodes to be inserted to any CI step.
# This ensure the pipeline will be triggered only for these scenarios.
# Theses lines should never be modified.
.run_by_main: &run_by_main
  only:
  - devel
  - merge_requests
  - web
  except:
    variables:
      # Skip MR labeled "CI::Disabled"
      - $CI_MERGE_REQUEST_LABELS =~ /CI::Disabled/

.uses_slurm: &uses_slurm
  tags:
    - slurm


############################
##### EXTRA ACTIONS ########
############################
#these actions should herit from implicit stages ".pre" and ".post"

# pre-actions to cleanup the machine before the run
# this job will be run in ANY pipeline -> ensure to enable all proper tags
# CAUTION : Otherwise tag-specific runners won't allow to run the whole pipeline because
# both .pre and .post cannot be scheduled (thus, why not using user-defined pre and post
# to avoid them to be run systematically ?)
Env Sanitize:
  <<: *run_by_main
  stage: Initialization
  script:
    - test -d $GL_PIPELINE_PATH && rm -rf $GL_PIPELINE_PATH
    - mkdir -p $GL_PIPELINE_PATH

Resource Relinquishing:
  <<: *run_by_main
  <<: *uses_slurm
  stage: Finalization
  when: always
  script:
  # FIXME: re-setup job canncellation.
  - scancel --name GL-build_$CI_PIPELINE_ID
  # Ugly, our way to kill allocations from tests
  - scancel -u $USER

############################
####### CONF STAGE  ########
############################
.conf_run_cmds: &configuration_commands
  - echo "${GL_BUILD_DIR}"
  - echo "${GL_INSTALL_DIR}"
  - rm -rf ${GL_LOCAL_BUILD_DIR} ${GL_LOCAL_INSTALL_DIR}
  - mkdir ${GL_LOCAL_BUILD_DIR}; cd ${GL_LOCAL_BUILD_DIR}
  - source "$(ccc_home -u mpc)"/gitlab-runner/spack_organizer_inti/setup.sh
  - spack env activate pcvs
  - module load pmix
  - ln -sf "$(ccc_home -u mpc)"/mpc_deps "${HOME}"/.mpcdep
  - ${CI_PROJECT_DIR}/installmpc -vv --prefix=${GL_LOCAL_INSTALL_DIR} ${GL_INSTALL_OPTS}
  - spack env deactivate

# Default configuration need pmix to work on inti.
MPC Default Configuration:
  <<: *run_by_main
  stage: Regular Installation
  variables:
    GL_LOCAL_BUILD_DIR: ${GL_BUILD_DIR}
    GL_LOCAL_INSTALL_DIR: ${GL_INSTALL_DIR}
    GL_INSTALL_OPTS: --enable-debug --with-pmix
  script:
    - *configuration_commands
  artifacts:
    paths:
      - ${GL_LOCAL_INSTALL_DIR}

MPC Process Mode (no Spack):
  <<: *run_by_main
  stage: Configurations
  variables:
    GL_LOCAL_BUILD_DIR: ${GL_BUILD_DIR}_nopriv_no_spack
    GL_LOCAL_INSTALL_DIR: ${GL_INSTALL_DIR}_nopriv
    GL_INSTALL_OPTS: --disable-mpc-autopriv --disable-spack
  script:
    - *configuration_commands

MPC Process Mode:
  <<: *run_by_main
  stage: Configurations
  variables:
    GL_LOCAL_BUILD_DIR: ${GL_BUILD_DIR}_nopriv
    GL_LOCAL_INSTALL_DIR: ${GL_INSTALL_DIR}_nopriv
    GL_INSTALL_OPTS: --disable-mpc-autopriv
  script:
    - *configuration_commands

MPC Disable Lowcomm:
  <<: *run_by_main
  stage: Configurations
  variables:
    GL_LOCAL_BUILD_DIR: ${GL_BUILD_DIR}_nolowcomm
    GL_LOCAL_INSTALL_DIR: ${GL_INSTALL_DIR}_nolowcomm
    GL_INSTALL_OPTS: --disable-mpc-autopriv --mpc-option="--disable-lowcomm"
  script:
    - *configuration_commands

MPC Disable MPI:
  <<: *run_by_main
  stage: Configurations
  variables:
    GL_LOCAL_BUILD_DIR: ${GL_BUILD_DIR}_nompi
    GL_LOCAL_INSTALL_DIR: ${GL_INSTALL_DIR}_nompi
    GL_INSTALL_OPTS: --disable-mpc-autopriv --mpc-option="--disable-mpi"
  script:
    - *configuration_commands

MPC Disable Threads:
  <<: *run_by_main
  stage: Configurations
  variables:
    GL_LOCAL_BUILD_DIR: ${GL_BUILD_DIR}_nothread
    GL_LOCAL_INSTALL_DIR: ${GL_INSTALL_DIR}_nothread
    GL_INSTALL_OPTS: --disable-mpc-autopriv --mpc-option="--disable-threads"
  script:
    - *configuration_commands

MPC Debug Messages:
  <<: *run_by_main
  stage: Configurations
  variables:
    GL_LOCAL_BUILD_DIR: ${GL_BUILD_DIR}_debug
    GL_LOCAL_INSTALL_DIR: ${GL_INSTALL_DIR}_debug
    GL_INSTALL_OPTS: --disable-mpc-autopriv --enable-debug
  script:
    - *configuration_commands

MPC Slurm:
  <<: *run_by_main
  stage: Configurations
  variables:
    GL_LOCAL_BUILD_DIR: ${GL_BUILD_DIR}_slurm
    GL_LOCAL_INSTALL_DIR: ${GL_INSTALL_DIR}_slurm
    GL_INSTALL_OPTS: --disable-mpc-autopriv --with-slurm
  script:
    - *configuration_commands

MPC Disable PMIX:
  <<: *run_by_main
  stage: Configurations
  variables:
    GL_LOCAL_BUILD_DIR: ${GL_BUILD_DIR}_nopmix
    GL_LOCAL_INSTALL_DIR: ${GL_INSTALL_DIR}_nopmix
    GL_INSTALL_OPTS: --disable-mpc-autopriv
  script:
    - *configuration_commands

# NOTE: Will fail
MPC Compilation Workshare:
  <<: *run_by_main
  stage: Configurations
  variables:
    GL_LOCAL_BUILD_DIR: ${GL_BUILD_DIR}_workshare
    GL_LOCAL_INSTALL_DIR: ${GL_INSTALL_DIR}_workshare
    GL_INSTALL_OPTS: --enable-workshare --enable-debug
  allow_failure: true
  script:
    - *configuration_commands

############################
####### TEST STAGE ########
############################

#
# Basic Testing
# to stop the pipeline early in case of major issue 
# (not able to compile/run a simple test)
#

Simple run:
  <<: *run_by_main
  <<: *uses_slurm
  stage: Basic Testing
  script:
    - *pcvs_prepare
    - ${PCVS_COMMAND} "${GL_PIPELINE_PATH}/mpc_ci/trivial/"

Privatization:
  <<: *run_by_main
  <<: *uses_slurm
  stage: Basic Testing
  script:
    - *pcvs_prepare
    - ${PCVS_COMMAND} "${GL_PIPELINE_PATH}/mpc_ci/privatization/"

#
# Regular Testing
# to assess some basic MPC feature
#

Lowcomm:
  <<: *run_by_main
  <<: *uses_slurm
  stage: Regular Testing
  script:
    - *pcvs_prepare
    - ${PCVS_COMMAND} "${GL_PIPELINE_PATH}/mpc_ci/lowcomm/"

MPI Simple C:
  <<: *run_by_main
  <<: *uses_slurm
  stage: Regular Testing
  script:
    - *pcvs_prepare
    - ${PCVS_COMMAND} "${GL_PIPELINE_PATH}/mpc_ci/MPI/simple/c/"

MPI Simple Fortran:
  <<: *run_by_main
  <<: *uses_slurm
  stage: Regular Testing
  script:
    - *pcvs_prepare
    - ${PCVS_COMMAND} "${GL_PIPELINE_PATH}/mpc_ci/MPI/simple/fortran/"

OpenMP Tasking examples:
  <<: *run_by_main
  <<: *uses_slurm
  stage: Regular Testing
  script:
    - *pcvs_prepare
    - ${PCVS_COMMAND} "${GL_PIPELINE_PATH}/mpc_ci/OpenMP/task/examples"

OpenMP Tasking cholesky:
  <<: *run_by_main
  <<: *uses_slurm
  stage: Regular Testing
  script:
    - *pcvs_prepare
    - module load llvm
    - module load lapack/mkl
    - ${PCVS_COMMAND} "${GL_PIPELINE_PATH}/mpc_ci/OpenMP/task/cholesky"

#
# Benchmarks
#

MPI IMB-MPI 2017:
  <<: *run_by_main
  <<: *uses_slurm
  stage: Benchmarks
  script:
    - *pcvs_prepare
    - ${PCVS_COMMAND} "${GL_PIPELINE_PATH}/mpc_ci/MPI/IMB_2017/check-mpi/"

MPI IMB-NBC 2017:
  <<: *run_by_main
  <<: *uses_slurm
  stage: Benchmarks
  script:
    - *pcvs_prepare
    - ${PCVS_COMMAND} "${GL_PIPELINE_PATH}/mpc_ci/MPI/IMB_2017/check-nbc/"

MPI NBC:
  <<: *run_by_main
  <<: *uses_slurm
  stage: Benchmarks
  script:
    - *pcvs_prepare
    - ${PCVS_COMMAND} "${GL_PIPELINE_PATH}/mpc_ci/MPI/NBC/"

#
# Applications
#

Lulesh:
  <<: *run_by_main
  <<: *uses_slurm
  stage: Applications
  script:
    - *pcvs_prepare
    - ${PCVS_COMMAND} "${GL_PIPELINE_PATH}/mpc_ci/corals/lulesh-2.0.3/"

NAS-MZ MPI:
  <<: *run_by_main
  <<: *uses_slurm
  stage: Applications
  script:
    - *pcvs_prepare
    - ${PCVS_COMMAND} "${GL_PIPELINE_PATH}/mpc_ci/hybrid/NAS/MZ-MPI/"

NAS-MZ OMP:
  <<: *run_by_main
  <<: *uses_slurm
  stage: Applications
  script:
    - *pcvs_prepare
    - ${PCVS_COMMAND} "${GL_PIPELINE_PATH}/mpc_ci/hybrid/NAS/MZ-OMP/"

miniFe:
  <<: *run_by_main
  <<: *uses_slurm
  stage: Applications
  script:
    - *pcvs_prepare
    - ${PCVS_COMMAND} "${GL_PIPELINE_PATH}/mpc_ci/corals/miniFe/"

###################################
####### MANUALLY TRIGGERED ########
###################################
#This section gathers jobs not scheduled to be part of the standard pipeline.
#They could be run manually or periodically.

#When triggered through a variable, MPC is built in containers with fixed software stack (base compiler, libc, etc...)
# to ensure MPC to compile in a large variety of environments

Debian Stretch:
  stage: Regular Testing
  script: "docker run --rm -it paratoolsfrance/mpc-env:debian-stretch $HOME/docker/run_installmpc.sh"
  tags:
    - "docker"
  only:
    variables:
      - $MPC_CI_MODE == "multibuild"

Centos 7:
  stage: Regular Testing
  script: "docker run --rm -it paratoolsfrance/mpc-env:centos-7 $HOME/docker/run_installmpc.sh"
  tags:
    - "docker"
  only:
    variables:
      - $MPC_CI_MODE == "multibuild"

release:
  stage: Release
  when: manual
  script: utils/release_all.sh $CI_PROJECT_DIR/$CI_PIPELINE_ID
  artifacts:
    paths:
      - $CI_PROJECT_DIR/$CI_PIPELINE_ID
